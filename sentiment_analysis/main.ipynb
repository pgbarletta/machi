{
 "metadata": {
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.3-final"
  },
  "orig_nbformat": 2,
  "kernelspec": {
   "name": "python3",
   "display_name": "Python 3.8.3 64-bit ('base': conda)",
   "metadata": {
    "interpreter": {
     "hash": "71f824c42634d496968419fb3b86a263c407c9e341d1af5774dc5baf7960dbd2"
    }
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2,
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [],
   "source": [
    "import project1 as p1\n",
    "import utils\n",
    "import numpy as np\n",
    "import random\n",
    "from string import punctuation, digits"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_order(n_samples):\n",
    "    try:\n",
    "        with open(str(n_samples) + '.txt') as fp:\n",
    "            line = fp.readline()\n",
    "            return list(map(int, line.split(',')))\n",
    "    except FileNotFoundError:\n",
    "        random.seed(1)\n",
    "        indices = list(range(n_samples))\n",
    "        random.shuffle(indices)\n",
    "        return indices"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [],
   "source": [
    "def accuracy(preds, targets):\n",
    "    \"\"\"\n",
    "    Given length-N vectors containing predicted and target labels,\n",
    "    returns the percentage and number of correct predictions.\n",
    "    \"\"\"\n",
    "    return (preds == targets).mean()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def hinge_loss_single(feature_vector, label, theta, theta_0):\n",
    "    \"\"\"\n",
    "    Finds the hinge loss on a single data point given specific classification\n",
    "    parameters.\n",
    "\n",
    "    Args:\n",
    "        feature_vector - A numpy array describing the given data point.\n",
    "        label - A real valued number, the correct classification of the data\n",
    "            point.\n",
    "        theta - A numpy array describing the linear classifier.\n",
    "        theta_0 - A real valued number representing the offset parameter.\n",
    "\n",
    "\n",
    "    Returns: A real number representing the hinge loss associated with the\n",
    "    given data point and parameters.\n",
    "    \"\"\"\n",
    "    \n",
    "    hinge_loss = max(0, 1 - label * (np.dot(feature_vector, theta) + theta_0))\n",
    "\n",
    "    return hinge_loss\n",
    "\n",
    "    raise NotImplementedError\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "feature_vector = np.array([5.85757831, 9.48411088, 4.71348922, 2.43062214, 4.27445804, 8.6418371, 1.03627538, 1.49498883, 1.42915177, 4.3454958, ])\n",
    "label = 1.\n",
    "theta = np.array([3.89173371, 3.7477549, 9.95500721, 9.86402351, 1.73976234, 3.71439254, 3.27476477, 2.76343474, 2.38647062, 6.69378231])\n",
    "theta_0 = 1."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "def hinge_loss_full(feature_matrix, labels, theta, theta_0):\n",
    "    \"\"\"\n",
    "    Finds the total hinge loss on a set of data given specific classification\n",
    "    parameters.\n",
    "\n",
    "    Args:\n",
    "        feature_matrix - A numpy matrix describing the given data. Each row\n",
    "            represents a single data point.\n",
    "        labels - A numpy array where the kth element of the array is the\n",
    "            correct classification of the kth row of the feature matrix.\n",
    "        theta - A numpy array describing the linear classifier.\n",
    "        theta_0 - A real valued number representing the offset parameter.\n",
    "\n",
    "\n",
    "    Returns: A real number representing the hinge loss associated with the\n",
    "    given dataset and parameters. This number should be the average hinge\n",
    "    loss across all of the points in the feature matrix.\n",
    "    \"\"\"\n",
    "    hinge_loss = []\n",
    "\n",
    "    for i in range(len(labels)):\n",
    "        hinge_loss.append(max(0, 1 - labels[i] * (np.dot(feature_matrix[i, :], theta) + theta_0)))\n",
    "\n",
    "    hinge_loss = np.array(hinge_loss)\n",
    "    \n",
    "    return np.mean(hinge_loss)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "feature_matrix = np.array([[1, 0], [1,0]])\n",
    "labels = np.array([1., -1.])\n",
    "theta = np.array([1, 0])\n",
    "theta_0 = 1."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "def perceptron_single_step_update(\n",
    "        feature_vector,\n",
    "        label,\n",
    "        current_theta,\n",
    "        current_theta_0):\n",
    "    \"\"\"\n",
    "    Properly updates the classification parameter, theta and theta_0, on a\n",
    "    single step of the perceptron algorithm.\n",
    "\n",
    "    Args:\n",
    "        feature_vector - A numpy array describing a single data point.\n",
    "        label - The correct classification of the feature vector.\n",
    "        current_theta - The current theta being used by the perceptron\n",
    "            algorithm before this update.\n",
    "        current_theta_0 - The current theta_0 being used by the perceptron\n",
    "            algorithm before this update.\n",
    "\n",
    "    Returns: A tuple where the first element is a numpy array with the value of\n",
    "    theta after the current update has completed and the second element is a\n",
    "    real valued number with the value of theta_0 after the current updated has\n",
    "    completed.\n",
    "    \"\"\"\n",
    "    def less_than_zero(x):\n",
    "        neg_epsilon = -0.01\n",
    "        pos_epsilon = 0.01\n",
    "        return x < pos_epsilon\n",
    "    \n",
    "    mitad = np.dot(feature_vector, current_theta) + current_theta_0\n",
    "\n",
    "    if less_than_zero(label * mitad):\n",
    "        current_theta += label * feature_vector\n",
    "        current_theta_0 += label\n",
    "\n",
    "    return (current_theta, current_theta_0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "feature_vector = np.array([1., 0.])\n",
    "label = 1.\n",
    "current_theta = np.array([1., 1.])\n",
    "current_theta_0 = 0."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "def perceptron(feature_matrix, labels, T):\n",
    "    \"\"\"\n",
    "    Runs the full perceptron algorithm on a given set of data. Runs T\n",
    "    iterations through the data set, there is no need to worry about\n",
    "    stopping early.\n",
    "\n",
    "    NOTE: Please use the previously implemented functions when applicable.\n",
    "    Do not copy paste code from previous parts.\n",
    "\n",
    "    NOTE: Iterate the data matrix by the orders returned by get_order(feature_matrix.shape[0])\n",
    "\n",
    "    Args:\n",
    "        feature_matrix -  A numpy matrix describing the given data. Each row\n",
    "            represents a single data point.\n",
    "        labels - A numpy array where the kth element of the array is the\n",
    "            correct classification of the kth row of the feature matrix.\n",
    "        T - An integer indicating how many times the perceptron algorithm\n",
    "            should iterate through the feature matrix.\n",
    "\n",
    "    Returns: A tuple where the first element is a numpy array with the value of\n",
    "    theta, the linear classification parameter, after T iterations through the\n",
    "    feature matrix and the second element is a real number with the value of\n",
    "    theta_0, the offset classification parameter, after T iterations through\n",
    "    the feature matrix.\n",
    "    \"\"\"\n",
    "    theta = np.zeros(feature_matrix.shape[1])\n",
    "    theta_0 = 0.\n",
    "\n",
    "    for t in range(T):\n",
    "        for i in get_order(feature_matrix.shape[0]):\n",
    "            theta, theta_0 = perceptron_single_step_update(feature_matrix[i, :], labels[i], theta, theta_0)\n",
    "            pass\n",
    "    return (theta, theta_0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "feature_matrix = np.array([[1, 0], [1,1], [1, 1.5]])\n",
    "labels = np.array([1., -1., -1.])\n",
    "theta = np.zeros(feature_matrix.shape[1])\n",
    "theta_0 = 0."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "def average_perceptron(feature_matrix, labels, T):\n",
    "    \"\"\"\n",
    "    Runs the average perceptron algorithm on a given set of data. Runs T\n",
    "    iterations through the data set, there is no need to worry about\n",
    "    stopping early.\n",
    "\n",
    "    NOTE: Please use the previously implemented functions when applicable.\n",
    "    Do not copy paste code from previous parts.\n",
    "\n",
    "    NOTE: Iterate the data matrix by the orders returned by get_order(feature_matrix.shape[0])\n",
    "\n",
    "\n",
    "    Args:\n",
    "        feature_matrix -  A numpy matrix describing the given data. Each row\n",
    "            represents a single data point.\n",
    "        labels - A numpy array where the kth element of the array is the\n",
    "            correct classification of the kth row of the feature matrix.\n",
    "        T - An integer indicating how many times the perceptron algorithm\n",
    "            should iterate through the feature matrix.\n",
    "\n",
    "    Returns: A tuple where the first element is a numpy array with the value of\n",
    "    the average theta, the linear classification parameter, found after T\n",
    "    iterations through the feature matrix and the second element is a real\n",
    "    number with the value of the average theta_0, the offset classification\n",
    "    parameter, found after T iterations through the feature matrix.\n",
    "\n",
    "    Hint: It is difficult to keep a running average; however, it is simple to\n",
    "    find a sum and divide.\n",
    "    \"\"\"\n",
    "    dim = feature_matrix.shape[1]\n",
    "    nrows = feature_matrix.shape[0]\n",
    "    \n",
    "    theta = np.zeros(dim)\n",
    "    theta_sum = np.zeros(dim)\n",
    "    theta_0 = 0.\n",
    "    theta_0_sum = 0.\n",
    "\n",
    "    for t in range(T):\n",
    "        for i in get_order(nrows):\n",
    "            theta, theta_0 = perceptron_single_step_update(feature_matrix[i, :], labels [i], theta, theta_0)\n",
    "            theta_sum += theta\n",
    "            theta_0_sum += theta_0\n",
    "\n",
    "    theta_0_sum = theta_0_sum / (T * nrows)\n",
    "    theta_sum = theta_sum / (T * nrows)\n",
    "    \n",
    "    return (theta_sum, theta_0_sum)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 180,
   "metadata": {},
   "outputs": [],
   "source": [
    "average_perceptron(feature_matrix, labels, 5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {},
   "outputs": [],
   "source": [
    "def pegasos_single_step_update(\n",
    "        feature_vector,\n",
    "        label,\n",
    "        L,\n",
    "        eta,\n",
    "        current_theta,\n",
    "        current_theta_0):\n",
    "    \"\"\"\n",
    "    Properly updates the classification parameter, theta and theta_0, on a\n",
    "    single step of the Pegasos algorithm\n",
    "\n",
    "    Args:\n",
    "        feature_vector - A numpy array describing a single data point.\n",
    "        label - The correct classification of the feature vector.\n",
    "        L - The lamba value being used to update the parameters.\n",
    "        eta - Learning rate to update parameters.\n",
    "        current_theta - The current theta being used by the Pegasos\n",
    "            algorithm before this update.\n",
    "        current_theta_0 - The current theta_0 being used by the\n",
    "            Pegasos algorithm before this update.\n",
    "\n",
    "    Returns: A tuple where the first element is a numpy array with the value of\n",
    "    theta after the current update has completed and the second element is a\n",
    "    real valued number with the value of theta_0 after the current updated has\n",
    "    completed.\n",
    "    \"\"\"\n",
    "\n",
    "    mitad = np.dot(feature_vector, current_theta) + current_theta_0\n",
    "\n",
    "    if (label * mitad) <= 1:\n",
    "        current_theta = (1 - eta*L) * current_theta + label * eta * feature_vector\n",
    "        current_theta_0 += (label * eta)\n",
    "    else:\n",
    "        current_theta = (1 - eta*L) * current_theta\n",
    "\n",
    "    return (current_theta, current_theta_0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {},
   "outputs": [],
   "source": [
    "feature_vector = np.array([-0.2044347, 0.32582899, 0.16653248, 0.20351482, -0.25742085, -0.15420557, -0.35653458, -0.11924025, -0.06888927, -0.40490458])\n",
    "\n",
    "current_theta = np.array([-0.24304381, 0.39144603, -0.16014528, -0.28811461, 0.05726083, -0.37348628, 0.30518816, -0.45640571, 0.08291773, 0.23137106])\n",
    "\n",
    "\n",
    "label = 1.\n",
    "L = 0.5184870555601945\n",
    "eta = 0.5583661127186766\n",
    "\n",
    "current_theta_0 = 1.019003939895446"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {},
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "(array([-0.28683067,  0.46005208, -0.02079623, -0.09106804, -0.10305158,\n",
       "        -0.35146307,  0.01775765, -0.39085342,  0.02044715, -0.06169715]),\n",
       " 1.5773700526141226)"
      ]
     },
     "metadata": {},
     "execution_count": 64
    }
   ],
   "source": [
    "pegasos_single_step_update(feature_vector, label, L, eta,\n",
    "        current_theta, current_theta_0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 108,
   "metadata": {},
   "outputs": [],
   "source": [
    "def pegasos(feature_matrix, labels, T, L):\n",
    "    \"\"\"\n",
    "    Runs the Pegasos algorithm on a given set of data. Runs T\n",
    "    iterations through the data set, there is no need to worry about\n",
    "    stopping early.\n",
    "\n",
    "    For each update, set learning rate = 1/sqrt(t),\n",
    "    where t is a counter for the number of updates performed so far (between 1\n",
    "    and nT inclusive).\n",
    "\n",
    "    NOTE: Please use the previously implemented functions when applicable.\n",
    "    Do not copy paste code from previous parts.\n",
    "\n",
    "    Args:\n",
    "        feature_matrix - A numpy matrix describing the given data. Each row\n",
    "            represents a single data point.\n",
    "        labels - A numpy array where the kth element of the array is the\n",
    "            correct classification of the kth row of the feature matrix.\n",
    "        T - An integer indicating how many times the algorithm\n",
    "            should iterate through the feature matrix.\n",
    "        L - The lamba value being used to update the Pegasos\n",
    "            algorithm parameters.\n",
    "\n",
    "    Returns: A tuple where the first element is a numpy array with the value of\n",
    "    the theta, the linear classification parameter, found after T\n",
    "    iterations through the feature matrix and the second element is a real\n",
    "    number with the value of the theta_0, the offset classification\n",
    "    parameter, found after T iterations through the feature matrix.\n",
    "    \"\"\"\n",
    "    \n",
    "    dim = feature_matrix.shape[1]\n",
    "    nrows = feature_matrix.shape[0]\n",
    "    \n",
    "    theta = np.zeros(dim)\n",
    "    theta_0 = 0.\n",
    "    \n",
    "    t = 1\n",
    "    for j in range(T):\n",
    "        for i in get_order(nrows):\n",
    "            eta = 1 / np.sqrt(t)\n",
    "\n",
    "            theta, theta_0 = pegasos_single_step_update(feature_matrix[i, :], labels[i], L, eta, theta, theta_0)\n",
    "\n",
    "            t += 1\n",
    "    \n",
    "    return (theta, theta_0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 106,
   "metadata": {},
   "outputs": [],
   "source": [
    "feature_matrix = np.array([[0.1837462,0.29989789,-0.35889786,-0.30780561,-0.44230703,-0.03043835\n",
    ",0.21370063,0.33344998,-0.40850817,-0.13105809]\n",
    ",[0.08254096,0.06012654,0.19821234,0.40958367,0.07155838,-0.49830717\n",
    ",0.09098162,0.19062183,-0.27312663,0.39060785]\n",
    ",[-0.20112519,-0.00593087,0.05738862,0.16811148,-0.10466314,-0.21348009\n",
    ",0.45806193,-0.27659307,0.2901038,-0.29736505]\n",
    ",[-0.14703536,-0.45573697,-0.47563745,-0.08546162,-0.08562345,0.07636098\n",
    ",-0.42087389,-0.16322197,-0.02759763,0.0297091,] \n",
    ",[-0.18082261,0.28644149,-0.47549449,-0.3049562,0.13967768,0.34904474\n",
    ",0.20627692,0.28407868,0.21849356,-0.01642202]])\n",
    "\n",
    "\n",
    "labels = np.array([-1., -1., -1., 1., -1.])\n",
    "T = 10\n",
    "L = 0.1456692551041303"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 109,
   "metadata": {},
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "(array([-0.0788906 , -0.75570849, -0.31067529, -0.05412326, -0.13880071,\n",
       "         0.09435494, -0.74886923, -0.41457537, -0.07151218, -0.02349776]),\n",
       " -0.7607480018258824)"
      ]
     },
     "metadata": {},
     "execution_count": 109
    }
   ],
   "source": [
    "pegasos(feature_matrix, labels, T, L)"
   ]
  },
  {
   "source": [
    "## Ejercicios 7 en adelante"
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_data = utils.load_data('reviews_train.tsv')\n",
    "val_data = utils.load_data('reviews_val.tsv')\n",
    "test_data = utils.load_data('reviews_test.tsv')\n",
    "\n",
    "train_texts, train_labels = zip(*((sample['text'], sample['sentiment'])\n",
    "                                  for sample in train_data))\n",
    "val_texts, val_labels = zip(*((sample['text'], sample['sentiment'])\n",
    "                              for sample in val_data))\n",
    "test_texts, test_labels = zip(*((sample['text'], sample['sentiment'])\n",
    "                                for sample in test_data))\n",
    "\n",
    "dictionary = p1.bag_of_words(train_texts)\n",
    "\n",
    "train_bow_features = p1.extract_bow_feature_vectors(train_texts, dictionary)\n",
    "val_bow_features = p1.extract_bow_feature_vectors(val_texts, dictionary)\n",
    "test_bow_features = p1.extract_bow_feature_vectors(test_texts, dictionary)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [],
   "source": [
    "def classify(feature_matrix, theta, theta_0):\n",
    "    \"\"\"\n",
    "    A classification function that uses theta and theta_0 to classify a set of\n",
    "    data points.\n",
    "\n",
    "    Args:\n",
    "        feature_matrix - A numpy matrix describing the given data. Each row\n",
    "            represents a single data point.\n",
    "        theta - A numpy array describing the linear classifier.\n",
    "        theta_0 - A real valued number representing the offset parameter.\n",
    "\n",
    "    Returns: A numpy array of 1s and -1s where the kth element of the array is\n",
    "    the predicted classification of the kth row of the feature matrix using the\n",
    "    given theta and theta_0. If a prediction is GREATER THAN zero, it should\n",
    "    be considered a positive classification.\n",
    "    \"\"\"\n",
    "    def less_than_zero(x):\n",
    "        epsilon = 0.00001\n",
    "        return x < epsilon\n",
    "\n",
    "    rtdo = np.array([])\n",
    "    for i in range(0, feature_matrix.shape[0]):\n",
    "        mitad = np.dot(feature_matrix[i, :], theta) + theta_0\n",
    "        if less_than_zero(mitad):\n",
    "            rtdo = np.append(rtdo, -1.)\n",
    "        else:\n",
    "            rtdo = np.append(rtdo, 1.)\n",
    "            \n",
    "    return rtdo"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [],
   "source": [
    "feature_matrix = np.array([[1, 0], [1,1], [1, 1.5]])\n",
    "labels = np.array([1., -1., -1.])\n",
    "theta = np.zeros(feature_matrix.shape[1])\n",
    "theta_0 = 0."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "array([1., 1., 1.])"
      ]
     },
     "metadata": {},
     "execution_count": 48
    }
   ],
   "source": [
    "classify(feature_matrix, theta, theta_0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [],
   "source": [
    "def classifier_accuracy(\n",
    "        classifier,\n",
    "        train_feature_matrix,\n",
    "        val_feature_matrix,\n",
    "        train_labels,\n",
    "        val_labels,\n",
    "        **kwargs):\n",
    "    \"\"\"\n",
    "    Trains a linear classifier and computes accuracy.\n",
    "    The classifier is trained on the train data. The classifier's\n",
    "    accuracy on the train and validation data is then returned.\n",
    "\n",
    "    Args:\n",
    "        classifier - A classifier function that takes arguments\n",
    "            (feature matrix, labels, **kwargs) and returns (theta, theta_0)\n",
    "        train_feature_matrix - A numpy matrix describing the training\n",
    "            data. Each row represents a single data point.\n",
    "        val_feature_matrix - A numpy matrix describing the validation\n",
    "            data. Each row represents a single data point.\n",
    "        train_labels - A numpy array where the kth element of the array\n",
    "            is the correct classification of the kth row of the training\n",
    "            feature matrix.\n",
    "        val_labels - A numpy array where the kth element of the array\n",
    "            is the correct classification of the kth row of the validation\n",
    "            feature matrix.\n",
    "        **kwargs - Additional named arguments to pass to the classifier\n",
    "            (e.g. T or L)\n",
    "\n",
    "    Returns: A tuple in which the first element is the (scalar) accuracy of the\n",
    "    trained classifier on the training data and the second element is the\n",
    "    accuracy of the trained classifier on the validation data.\n",
    "    \"\"\"\n",
    "    \n",
    "    theta, theta_0 = classifier(train_feature_matrix, train_labels, **kwargs)\n",
    "    \n",
    "    rtdo_train_labels = classify(train_feature_matrix, theta, theta_0)\n",
    "    rtdo_val_labels = classify(val_feature_matrix, theta, theta_0)\n",
    "\n",
    "    train_acc = accuracy(rtdo_train_labels, train_labels)\n",
    "    val_acc = accuracy(rtdo_val_labels, val_labels)\n",
    "\n",
    "    return (train_acc, val_acc)\n",
    "\n",
    "    raise NotImplementedError\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "tuple"
      ]
     },
     "metadata": {},
     "execution_count": 51
    }
   ],
   "source": [
    "train_acc = .5\n",
    "train_val = .2\n",
    "type((train_acc, train_val))"
   ]
  },
  {
   "source": [
    "### otras"
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [],
   "source": [
    "def extract_words(input_string):\n",
    "    \"\"\"\n",
    "    Helper function for bag_of_words()\n",
    "    Inputs a text string\n",
    "    Returns a list of lowercase words in the string.\n",
    "    Punctuation and digits are separated out into their own words.\n",
    "    \"\"\"\n",
    "    for c in punctuation + digits:\n",
    "        input_string = input_string.replace(c, ' ' + c + ' ')\n",
    "\n",
    "    return input_string.lower().split()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 93,
   "metadata": {},
   "outputs": [],
   "source": [
    "def bag_of_words(texts):\n",
    "    \"\"\"\n",
    "    Inputs a list of string reviews\n",
    "    Returns a dictionary of unique unigrams occurring over the input\n",
    "\n",
    "    Feel free to change this code as guided by Problem 9\n",
    "    \"\"\"\n",
    "    f = open(\"stopwords.txt\", \"r\")\n",
    "    stopwrd = []\n",
    "    for line in f:\n",
    "        stopwrd.append(line[:-1])\n",
    "\n",
    "    dictionary = {}  # maps word to unique index\n",
    "    for text in texts:\n",
    "        word_list = extract_words(text)\n",
    "        for word in word_list:\n",
    "            if word not in dictionary and word not in stopwrd:\n",
    "                dictionary[word] = len(dictionary)\n",
    "    return dictionary"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def extract_bow_feature_vectors(reviews, dictionary):\n",
    "    \"\"\"\n",
    "    Inputs a list of string reviews\n",
    "    Inputs the dictionary of words as given by bag_of_words\n",
    "    Returns the bag-of-words feature matrix representation of the data.\n",
    "    The returned matrix is of shape (n, m), where n is the number of reviews\n",
    "    and m the total number of entries in the dictionary.\n",
    "\n",
    "    Feel free to change this code as guided by Problem 9\n",
    "    \"\"\"\n",
    "    # Your code here\n",
    "\n",
    "    num_reviews = len(reviews)\n",
    "    feature_matrix = np.zeros([num_reviews, len(dictionary)])\n",
    "\n",
    "    for i, text in enumerate(reviews):\n",
    "        word_list = extract_words(text)\n",
    "        for word in word_list:\n",
    "            if word in dictionary:\n",
    "                feature_matrix[i, dictionary[word]] = 1\n",
    "    return feature_matrix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 94,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "dictionary = bag_of_words(train_texts)\n",
    "\n"
   ]
  }
 ]
}